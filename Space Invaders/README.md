Deep Reinforcement Learning for Space Invaders

Project Description
This project demonstrates the use of deep reinforcement learning (DRL) to play the classic Space Invaders game using the OpenAI Gym environment. The agent is trained using a Deep Q-Network (DQN) implemented with Keras-RL.

Table of Contents

1. Introduction
2. Technologies Used
3. Requirements
4. Installation Instructions
5. Usage Instructions
6. Features
7. Dataset
8. Model
9. Results
10. Documentation
11. Visuals
12. Conclusion

Introduction
This project explores the application of DRL to the game Space Invaders. The agent is trained to maximize its score by learning optimal actions through trial and error. The model uses a convolutional neural network (CNN) to process the game's visual input and a DQN to make decisions.

Technologies Used
Python
OpenAI Gym
Pygame
TensorFlow/Keras
Keras-RL

Requirements
Python 3.7 or higher
OpenAI Gym
Pygame
TensorFlow
Keras-RL

Installation Instructions
1. Clone the repository:
git clone https://github.com/your-repo/space-invaders-drl.git

2. Install the required packages:
pip install -r requirements.txt

3. Ensure you have the Space Invaders environment installed:
pip install gym[atari]

Usage Instructions

1. Test a random environment:

import gym
import random

env = gym.make("SpaceInvaders-v0")
episodes = 5
for episode in range(1, episodes+1):
    state = env.reset()
    done = False
    score = 0 
    while not done:
        env.render()
        action = random.choice([0,1,2,3,4,5])
        n_state, reward, done, info = env.step(action)
        score += reward
    print('Episode:{} Score:{}'.format(episode, score))
env.close()

2. Create and train the model:

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Convolution2D
from tensorflow.keras.optimizers import Adam
from rl.agents import DQNAgent
from rl.memory import SequentialMemory
from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy

def build_model(height, width, channels, actions):
    model = Sequential()
    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu', input_shape=(3,height, width, channels)))
    model.add(Convolution2D(64, (4,4), strides=(2,2), activation='relu'))
    model.add(Convolution2D(64, (3,3), activation='relu'))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(256, activation='relu'))
    model.add(Dense(actions, activation='linear'))
    return model

def build_agent(model, actions):
    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)
    memory = SequentialMemory(limit=1000, window_length=3)
    dqn = DQNAgent(model=model, memory=memory, policy=policy,
                   enable_dueling_network=True, dueling_type='avg',
                   nb_actions=actions, nb_steps_warmup=1000)
    return dqn

env = gym.make("SpaceInvaders-v0")
height, width, channels = env.observation_space.shape
actions = env.action_space.n
model = build_model(height, width, channels, actions)
dqn = build_agent(model, actions)
dqn.compile(Adam(lr=1e-4))
dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)

Features
Play Space Invaders using a trained DRL agent
Random action environment testing
Model training and evaluation
Save and load model weights

Dataset
The dataset used in this project is the visual and game state data generated by the Space Invaders environment in OpenAI Gym.

Model
The model architecture includes:
Three convolutional layers
Flatten layer
Two dense layers
Output layer with a linear activation function

Results
The agent was trained for 10000 steps, achieving a mean reward of 208.5 during testing.

Documentation
Further documentation on the usage of OpenAI Gym, TensorFlow/Keras, and Keras-RL can be found on their respective websites:

OpenAI Gym
TensorFlow
Keras-RL

Conclusion
This project demonstrates the potential of DRL in playing video games. With further tuning and more training steps, the agent's performance could be improved.